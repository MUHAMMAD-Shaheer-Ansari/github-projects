{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,GlobalMaxPooling1D,Embedding,TextVectorization,LayerNormalization,MultiHeadAttention)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "ZslyJl_QV7rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../content/twitter_training.csv')\n",
        "df.columns = ['1','2','Sentiment','Sentence']\n",
        "df.drop(['1','2'],axis = 1,inplace = True)\n",
        "Y = np.array(pd.get_dummies(df['Sentiment']))\n",
        "classes = list(pd.get_dummies(df['Sentiment']))\n",
        "Y_train = []\n",
        "sen = []\n",
        "sentences = list(df['Sentence'])\n",
        "for i in range(len(sentences)):\n",
        "  if type(sentences[i]) != str:\n",
        "    pass\n",
        "  else:\n",
        "    sentences[i] = sentences[i].lower()\n",
        "    Y_train.append(Y[i])\n",
        "    sen.append(sentences[i])\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sen)\n",
        "seq = tokenizer.texts_to_sequences(sen)\n",
        "X_train = pad_sequences(seq , padding = 'post')\n",
        "seq_len = X_train.shape[1]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "Y_train = np.array(np.argmax(Y_train,axis = 1))"
      ],
      "metadata": {
        "id": "VglalYtM8eIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def positional_encoding(seq_len , model_size):\n",
        "  output = []\n",
        "  for pos in range(seq_len):\n",
        "    PE = np.zeros(model_size)\n",
        "    for i in range(model_size):\n",
        "      if i % 2 == 0:\n",
        "        PE[i] = np.sin(pos / (10000 ** (i/model_size)))\n",
        "      else:\n",
        "        PE[i] = np.cos(pos / (10000 ** ((i-1)/model_size)))\n",
        "\n",
        "    output.append(PE)\n",
        "    out = np.expand_dims(output , axis = 0)\n",
        "\n",
        "  return out\n",
        "\n",
        "class Embeddings(Layer):\n",
        "  def __init__(self , vocab_size , seq_len , model_size):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.emb = Embedding(input_dim = vocab_size , output_dim = model_size)\n",
        "    self.pos_encoding = positional_encoding(seq_len,model_size)\n",
        "\n",
        "  def call(self,input):\n",
        "    embs = self.emb(input)\n",
        "    return (self.pos_encoding + embs)\n",
        "\n",
        "  def compute_masks(self,input):\n",
        "    mask = tf.math.not_equal(input , 0)\n",
        "    mask = tf.cast(mask[:,tf.newaxis,:],tf.int32)\n",
        "    T = tf.shape(mask)[2]\n",
        "    mask = tf.repeat(mask , T , axis = 1)\n",
        "\n",
        "    return mask\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "  def __init__(self, num_heads , emb_dim , dense_dim):\n",
        "    super(TransformerEncoder,self).__init__()\n",
        "    self.layernorm_1 = LayerNormalization()\n",
        "    self.layernorm_2 = LayerNormalization()\n",
        "    self.dense = tf.keras.Sequential([\n",
        "        Dense(dense_dim,activation = 'relu'),\n",
        "        Dense(emb_dim)\n",
        "    ])\n",
        "    self.attn = MultiHeadAttention(num_heads=num_heads,key_dim=emb_dim)\n",
        "\n",
        "  def call(self,inputs , mask):\n",
        "    attn_out = self.attn(query = inputs , key = inputs , value = inputs , attention_mask = mask)\n",
        "    out = self.layernorm_1(attn_out + inputs)\n",
        "\n",
        "    dense_out = self.dense(out)\n",
        "\n",
        "    return self.layernorm_2(dense_out + out)\n",
        "\n"
      ],
      "metadata": {
        "id": "-WygdnyllCc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=256\n",
        "D_FF=1024\n",
        "NUM_HEADS=4\n",
        "NUM_LAYERS=1\n",
        "NUM_EPOCHS=20"
      ],
      "metadata": {
        "id": "NXt45DIei57j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input=Input(shape=(None,))\n",
        "emb = Embeddings(vocab_size,seq_len,EMBEDDING_DIM)\n",
        "x = emb(encoder_input)\n",
        "padding_mask = emb.compute_masks(encoder_input)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  x=TransformerEncoder(NUM_HEADS,EMBEDDING_DIM,D_FF)(x,padding_mask)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output=Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    encoder_input, output\n",
        ")\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1QlE5KTi59i",
        "outputId": "944d3177-65b4-4dfd-a0a1-49d5dedd54b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " tf.math.not_equal_5 (TFOpL  (None, None)                 0         ['input_6[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, None)              0         ['tf.math.not_equal_5[0][0]'] \n",
            " 0 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.cast_5 (TFOpLambda)      (None, 1, None)              0         ['tf.__operators__.getitem_10[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_5 (TFOp  (3,)                         0         ['tf.cast_5[0][0]']           \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_5[0][0]']\n",
            " 1 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " embeddings_5 (Embeddings)   (None, 166, 256)             8648704   ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " tf.repeat_5 (TFOpLambda)    (None, None, None)           0         ['tf.cast_5[0][0]',           \n",
            "                                                                     'tf.__operators__.getitem_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " transformer_encoder_8 (Tra  (None, 166, 256)             1578496   ['embeddings_5[0][0]',        \n",
            " nsformerEncoder)                                                    'tf.repeat_5[0][0]']         \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 42496)                0         ['transformer_encoder_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 42496)                0         ['flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 4)                    169988    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10397188 (39.66 MB)\n",
            "Trainable params: 10397188 (39.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "dZk99Zr3_pu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UkS7jN3yjYH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=transformer.fit(\n",
        "    X_train[:1000] , Y_train[:1000],\n",
        "    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH_RD74TjE6G",
        "outputId": "9c3000e0-fedd-454e-c6ba-63d0747b9474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 55s 2s/step - loss: 10.2081 - accuracy: 0.2870\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 53s 2s/step - loss: 2.9610 - accuracy: 0.3120\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 54s 2s/step - loss: 3.1273 - accuracy: 0.3230\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 53s 2s/step - loss: 2.3248 - accuracy: 0.3020\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 54s 2s/step - loss: 2.1964 - accuracy: 0.2970\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 52s 2s/step - loss: 2.4834 - accuracy: 0.2760\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 51s 2s/step - loss: 1.7188 - accuracy: 0.4500\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 54s 2s/step - loss: 1.2222 - accuracy: 0.5830\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 53s 2s/step - loss: 0.7914 - accuracy: 0.7480\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 54s 2s/step - loss: 0.6084 - accuracy: 0.8290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOVGz-4SGWHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}